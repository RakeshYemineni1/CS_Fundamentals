export const memoryManagementTopics = [
  {
    id: 'memory-management-complete',
    title: 'Memory Management - Complete Guide',
    subtitle: 'Allocation, Paging, Segmentation, and Virtual Memory',
    
    summary: 'Memory management handles allocation, deallocation, and organization of system memory. It provides memory protection, enables multiprogramming, implements virtual memory through paging and segmentation, and optimizes memory utilization through various allocation strategies.',
    
    analogy: 'Think of memory like a hotel: Memory manager is the receptionist who assigns rooms (memory blocks) to guests (processes). Paging is like having identical-sized rooms that can be assigned anywhere. Segmentation is like having different room types (suites, standard) for different purposes. Virtual memory is like overbooking - promising more rooms than physically available, knowing not all guests arrive simultaneously.',
    
    explanation: `MEMORY MANAGEMENT - COMPREHENSIVE GUIDE

Memory management is one of the most critical functions of an operating system, responsible for efficient allocation, tracking, and protection of system memory.

CORE RESPONSIBILITIES:

1. MEMORY ALLOCATION - Assigning memory blocks to processes
2. MEMORY DEALLOCATION - Reclaiming memory when processes terminate
3. MEMORY PROTECTION - Preventing processes from accessing each other's memory
4. MEMORY TRACKING - Maintaining information about allocated and free memory
5. ADDRESS TRANSLATION - Converting logical addresses to physical addresses
6. MEMORY OPTIMIZATION - Maximizing memory utilization and performance

MEMORY HIERARCHY:

Registers (fastest, smallest) → Cache (L1, L2, L3) → Main Memory (RAM) → Secondary Storage (disk, slowest, largest)

Memory management primarily deals with main memory (RAM) and secondary storage.

LOGICAL VS PHYSICAL ADDRESSES:

LOGICAL ADDRESS (Virtual Address):
- Generated by CPU during program execution
- Used by processes in their programs
- Address space: 0 to MAX (e.g., 0 to 2^32-1 for 32-bit)
- Process thinks it has contiguous memory starting at 0
- Example: Process accesses address 0x1000

PHYSICAL ADDRESS:
- Actual location in physical RAM
- Used by memory hardware
- May be completely different from logical address
- Example: Logical 0x1000 maps to physical 0x5000

Memory Management Unit (MMU) translates logical to physical addresses.

MEMORY ALLOCATION STRATEGIES:

1. CONTIGUOUS ALLOCATION:

All memory for a process is allocated in a single contiguous block.

FIXED PARTITIONING:
- Divide memory into fixed-size partitions
- Each partition holds one process
- Simple but causes internal fragmentation
- Partition size may not match process size

VARIABLE PARTITIONING:
- Allocate exactly the size needed by process
- No internal fragmentation
- Causes external fragmentation over time
- Requires allocation algorithms

2. NON-CONTIGUOUS ALLOCATION:

Process memory can be scattered across physical memory.

PAGING:
- Divide logical memory into fixed-size pages
- Divide physical memory into fixed-size frames
- Page size = Frame size (typically 4KB)
- No external fragmentation
- Small internal fragmentation (last page)

SEGMENTATION:
- Divide program into logical segments (code, data, stack, heap)
- Each segment can be different size
- Matches program structure
- External fragmentation possible

MEMORY ALLOCATION ALGORITHMS:

For variable partitioning, when a process requests memory, which free block to allocate?

1. FIRST FIT:
- Allocate first block large enough
- Fast (stops searching when found)
- May leave small unusable fragments at beginning

2. BEST FIT:
- Allocate smallest block large enough
- Minimizes wasted space
- Slow (must search entire list)
- Creates tiny unusable fragments

3. WORST FIT:
- Allocate largest available block
- Leaves larger remaining fragments
- Slow (must search entire list)
- Poor memory utilization

4. NEXT FIT:
- Like First Fit but starts search from last allocation
- Distributes allocations more evenly
- Slightly slower than First Fit

FRAGMENTATION:

INTERNAL FRAGMENTATION:
- Wasted space within allocated block
- Occurs when allocated block is larger than requested
- Example: Process needs 18KB, gets 20KB partition → 2KB wasted
- Solution: Use smaller allocation units, variable partitioning

EXTERNAL FRAGMENTATION:
- Free memory scattered in small non-contiguous blocks
- Total free memory sufficient but not contiguous
- Example: 100KB free in 10KB chunks, can't allocate 50KB process
- Solution: Compaction, paging, segmentation with paging

COMPACTION:
- Move all allocated blocks to one end
- Combine all free space into one large block
- Expensive: must update all pointers, pause processes
- Only feasible with dynamic relocation

PAGING - DETAILED:

CONCEPT:
- Logical memory divided into pages (fixed size, e.g., 4KB)
- Physical memory divided into frames (same size as pages)
- Any page can be loaded into any frame
- No external fragmentation

PAGE TABLE:
- Maps page numbers to frame numbers
- One entry per page
- Stored in main memory
- Page Table Base Register (PTBR) points to page table

ADDRESS TRANSLATION:
Logical Address = (Page Number, Offset)
Physical Address = (Frame Number, Offset)

Example: 32-bit address, 4KB pages
- Page size = 4KB = 2^12 bytes
- Offset = 12 bits (0-4095)
- Page number = 20 bits (2^20 = 1M pages)

Logical address 0x00003ABC:
- Page number = 0x00003 = 3
- Offset = 0xABC = 2748
- If page 3 maps to frame 7:
- Physical address = (7 * 4096) + 2748 = 0x00007ABC

TRANSLATION LOOKASIDE BUFFER (TLB):

Problem: Page table in memory → 2 memory accesses per instruction (1 for page table, 1 for data)

Solution: TLB - small, fast cache of recent page table entries

TLB Hit: Translation found in TLB (fast, 1 memory access)
TLB Miss: Must access page table (slow, 2 memory accesses)

TLB Hit Ratio: Percentage of translations found in TLB (typically 90-99%)

Effective Access Time = (TLB Hit Ratio × TLB Access Time) + (TLB Miss Ratio × Page Table Access Time)

MULTI-LEVEL PAGING:

Problem: Large page tables consume too much memory
Example: 32-bit address, 4KB pages → 1M entries × 4 bytes = 4MB per process

Solution: Multi-level page table (hierarchical)

TWO-LEVEL PAGING:
- Outer page table (small, always in memory)
- Inner page tables (can be paged out)
- Logical address = (Outer Page, Inner Page, Offset)

Example: 32-bit address, 4KB pages, 4-byte entries
- 10 bits outer page (1024 entries)
- 10 bits inner page (1024 entries)
- 12 bits offset (4096 bytes)
- Saves memory: Only need outer table + active inner tables

INVERTED PAGE TABLE:
- One entry per frame (not per page)
- Reduces memory for page table
- Slower lookup (must search)
- Used in some systems (PowerPC)

SEGMENTATION - DETAILED:

CONCEPT:
- Divide program into logical segments
- Each segment represents logical unit (code, data, stack, heap)
- Segments can be different sizes
- Matches programmer's view of program

SEGMENT TABLE:
- One entry per segment
- Each entry contains: Base (starting physical address), Limit (segment length)

ADDRESS TRANSLATION:
Logical Address = (Segment Number, Offset)

Steps:
1. Check if offset < limit (protection)
2. Physical Address = Base + Offset

Example:
Segment 2: Base = 4300, Limit = 400
Logical address (2, 53):
- Check: 53 < 400 ✓
- Physical = 4300 + 53 = 4353

ADVANTAGES:
- Matches program structure
- Easy to share code segments
- Protection at segment level
- Dynamic growth of segments

DISADVANTAGES:
- External fragmentation
- Complex memory allocation
- Segment table overhead

SEGMENTATION WITH PAGING:

Combines benefits of both:
- Segment program logically (programmer's view)
- Page each segment (eliminate external fragmentation)

Used in: Intel x86 architecture

Logical Address = (Segment, Page, Offset)
1. Use segment number to get segment table entry
2. Use page number to index into segment's page table
3. Get frame number, add offset

VIRTUAL MEMORY:

CONCEPT:
- Allows execution of processes not completely in memory
- Logical address space can be larger than physical memory
- Only needed pages loaded in memory
- Rest stored on disk (swap space)

BENEFITS:
1. Run programs larger than physical memory
2. More processes in memory (better multiprogramming)
3. Less I/O for loading/swapping
4. Efficient memory utilization

DEMAND PAGING:

Load pages only when needed (on demand).

PAGE FAULT:
Occurs when process accesses page not in memory.

Page Fault Handling:
1. Check if reference is valid (page table)
2. If invalid, terminate process
3. If valid but not in memory:
   a. Find free frame
   b. If no free frame, select victim page (page replacement)
   c. Write victim page to disk if modified (dirty bit)
   d. Load required page from disk to frame
   e. Update page table
   f. Restart instruction

PAGE REPLACEMENT ALGORITHMS:

When memory is full, which page to replace?

1. FIFO (First-In-First-Out):
- Replace oldest page in memory
- Simple to implement (queue)
- Suffers from Belady's Anomaly (more frames → more faults)
- Poor performance

2. OPTIMAL (OPT):
- Replace page that won't be used for longest time
- Theoretical best (impossible to implement)
- Used as benchmark for other algorithms
- Requires future knowledge

3. LRU (Least Recently Used):
- Replace page not used for longest time
- Approximates OPT
- Good performance
- Expensive to implement (need timestamps or stack)

4. LRU APPROXIMATION (Second Chance / Clock):
- Use reference bit (set by hardware on access)
- Scan pages in circular order
- If reference bit = 0, replace
- If reference bit = 1, set to 0 and give second chance
- Efficient approximation of LRU

5. COUNTING ALGORITHMS:
- LFU (Least Frequently Used): Replace page with lowest access count
- MFU (Most Frequently Used): Replace page with highest access count

THRASHING:

Process spends more time paging than executing.

Causes:
- Too many processes in memory
- Each process gets too few frames
- Constant page faults

Solution:
- Reduce degree of multiprogramming
- Use working set model
- Page fault frequency control

WORKING SET MODEL:

Working Set: Set of pages process is currently using

Working Set Window (Δ): Time window to track page references
- If page referenced in last Δ time, it's in working set
- Allocate enough frames to hold working set
- Prevents thrashing

ALLOCATION STRATEGIES:

How many frames to allocate to each process?

EQUAL ALLOCATION:
- Divide frames equally among processes
- Simple but unfair (different process sizes)

PROPORTIONAL ALLOCATION:
- Allocate based on process size
- Larger processes get more frames
- More fair

PRIORITY ALLOCATION:
- Allocate based on process priority
- High-priority processes get more frames

LOCAL vs GLOBAL REPLACEMENT:

LOCAL: Process can only replace its own pages
- Prevents one process from affecting others
- May not utilize memory efficiently

GLOBAL: Process can replace any page
- Better memory utilization
- One process can affect others
- More common in modern systems`,

    keyPoints: [
      'Memory management handles allocation, protection, and optimization of system memory',
      'Logical addresses (virtual) are translated to physical addresses by MMU',
      'Allocation algorithms: First Fit (fast), Best Fit (minimal waste), Worst Fit (large fragments)',
      'Internal fragmentation: wasted space within blocks; External fragmentation: scattered free space',
      'Paging: fixed-size pages/frames, eliminates external fragmentation, uses page tables',
      'TLB caches recent page translations, dramatically improves performance (90-99% hit ratio)',
      'Segmentation: variable-size logical units, matches program structure, external fragmentation',
      'Virtual memory: allows programs larger than physical memory, uses demand paging',
      'Page replacement algorithms: FIFO (simple), Optimal (theoretical), LRU (practical), Clock (efficient)',
      'Thrashing: excessive paging when too many processes compete for too few frames'
    ],

    codeExamples: [
      {
        title: 'Memory Allocation Algorithms',
        language: 'java',
        code: `class MemoryAllocator {
    List<Block> freeBlocks;
    
    // First Fit
    Block firstFit(int size) {
        for (Block b : freeBlocks)
            if (b.size >= size)
                return allocate(b, size);
        return null;
    }
    
    // Best Fit
    Block bestFit(int size) {
        Block best = null;
        int minWaste = Integer.MAX_VALUE;
        for (Block b : freeBlocks) {
            if (b.size >= size && b.size - size < minWaste) {
                minWaste = b.size - size;
                best = b;
            }
        }
        return best != null ? allocate(best, size) : null;
    }
    
    // Worst Fit
    Block worstFit(int size) {
        Block worst = null;
        int maxSize = 0;
        for (Block b : freeBlocks) {
            if (b.size >= size && b.size > maxSize) {
                maxSize = b.size;
                worst = b;
            }
        }
        return worst != null ? allocate(worst, size) : null;
    }
}`,
        description: 'Three main allocation algorithms with minimal implementation'
      },
      {
        title: 'Paging - Address Translation',
        language: 'java',
        code: `class Paging {
    int pageSize = 4096; // 4KB
    int[] pageTable;
    
    int translate(int logicalAddr) {
        int pageNum = logicalAddr / pageSize;
        int offset = logicalAddr % pageSize;
        int frameNum = pageTable[pageNum];
        return frameNum * pageSize + offset;
    }
}

class TLB {
    Map<Integer, Integer> cache = new HashMap<>();
    
    Integer lookup(int pageNum) {
        return cache.get(pageNum);
    }
    
    void update(int pageNum, int frameNum) {
        if (cache.size() >= 64) cache.remove(cache.keySet().iterator().next());
        cache.put(pageNum, frameNum);
    }
}`,
        description: 'Paging with TLB for fast address translation'
      },
      {
        title: 'Segmentation - Address Translation',
        language: 'java',
        code: `class Segmentation {
    class SegmentEntry {
        int base, limit;
    }
    SegmentEntry[] segmentTable;
    
    int translate(int segment, int offset) {
        SegmentEntry entry = segmentTable[segment];
        if (offset >= entry.limit)
            throw new SegmentationFault();
        return entry.base + offset;
    }
}`,
        description: 'Segmentation with bounds checking'
      },
      {
        title: 'Page Replacement - FIFO',
        language: 'java',
        code: `class FIFO {
    Queue<Integer> queue = new LinkedList<>();
    Set<Integer> pages = new HashSet<>();
    int capacity;
    
    int pageFault(int page) {
        if (pages.contains(page)) return 0;
        
        if (pages.size() == capacity) {
            int victim = queue.poll();
            pages.remove(victim);
        }
        queue.offer(page);
        pages.add(page);
        return 1;
    }
}`,
        description: 'FIFO page replacement algorithm'
      },
      {
        title: 'Page Replacement - LRU',
        language: 'java',
        code: `class LRU {
    LinkedHashMap<Integer, Integer> cache;
    int capacity;
    
    LRU(int cap) {
        capacity = cap;
        cache = new LinkedHashMap<>(cap, 0.75f, true);
    }
    
    int pageFault(int page) {
        if (cache.containsKey(page)) {
            cache.get(page); // Update access order
            return 0;
        }
        
        if (cache.size() == capacity)
            cache.remove(cache.keySet().iterator().next());
        cache.put(page, page);
        return 1;
    }
}`,
        description: 'LRU using LinkedHashMap for access order'
      },
      {
        title: 'Page Replacement - Clock (Second Chance)',
        language: 'java',
        code: `class Clock {
    int[] pages;
    boolean[] refBit;
    int hand = 0, size = 0, capacity;
    
    int pageFault(int page) {
        for (int i = 0; i < size; i++)
            if (pages[i] == page) {
                refBit[i] = true;
                return 0;
            }
        
        while (true) {
            if (!refBit[hand]) {
                pages[hand] = page;
                refBit[hand] = true;
                hand = (hand + 1) % capacity;
                if (size < capacity) size++;
                return 1;
            }
            refBit[hand] = false;
            hand = (hand + 1) % capacity;
        }
    }
}`,
        description: 'Clock algorithm with reference bits'
      },
      {
        title: 'Buddy System Allocation',
        language: 'java',
        code: `class BuddySystem {
    Map<Integer, List<Integer>> freeBlocks = new HashMap<>();
    int maxSize;
    
    int allocate(int size) {
        int blockSize = nextPowerOf2(size);
        if (freeBlocks.containsKey(blockSize) && !freeBlocks.get(blockSize).isEmpty())
            return freeBlocks.get(blockSize).remove(0);
        
        int largerSize = blockSize * 2;
        while (largerSize <= maxSize) {
            if (freeBlocks.containsKey(largerSize) && !freeBlocks.get(largerSize).isEmpty()) {
                int block = freeBlocks.get(largerSize).remove(0);
                split(block, largerSize);
                return freeBlocks.get(blockSize).remove(0);
            }
            largerSize *= 2;
        }
        return -1;
    }
    
    void split(int block, int size) {
        int halfSize = size / 2;
        freeBlocks.computeIfAbsent(halfSize, k -> new ArrayList<>()).add(block);
        freeBlocks.get(halfSize).add(block + halfSize);
    }
}`,
        description: 'Buddy system with power-of-2 allocation'
      }
    ],

    resources: [
      { 
        title: 'GeeksforGeeks - Memory Management', 
        url: 'https://www.geeksforgeeks.org/memory-management-in-operating-system/',
        description: 'Comprehensive guide to memory management concepts'
      },
      { 
        title: 'TutorialsPoint - Memory Management', 
        url: 'https://www.tutorialspoint.com/operating_system/os_memory_management.htm',
        description: 'Detailed explanation with examples'
      },
      { 
        title: 'JavaTpoint - Paging in OS', 
        url: 'https://www.javatpoint.com/os-paging',
        description: 'Paging concepts with diagrams'
      },
      { 
        title: 'GeeksforGeeks - Page Replacement Algorithms', 
        url: 'https://www.geeksforgeeks.org/page-replacement-algorithms-in-operating-systems/',
        description: 'All page replacement algorithms explained'
      },
      { 
        title: 'YouTube - Neso Academy Memory Management', 
        url: 'https://www.youtube.com/watch?v=qdkxXygc3rE',
        description: 'Video series on memory management'
      },
      { 
        title: 'YouTube - Gate Smashers Paging', 
        url: 'https://www.youtube.com/watch?v=pJ6qrCB8pDw',
        description: 'Paging and virtual memory explained'
      },
      { 
        title: 'Operating System Concepts - Silberschatz', 
        url: 'https://www.os-book.com/',
        description: 'Classic textbook chapters on memory management'
      },
      { 
        title: 'MIT OpenCourseWare - Memory Management', 
        url: 'https://ocw.mit.edu/',
        description: 'Free course materials on memory systems'
      },
      { 
        title: 'Virtual Memory Tutorial', 
        url: 'https://www.geeksforgeeks.org/virtual-memory-in-operating-system/',
        description: 'Virtual memory and demand paging'
      },
      { 
        title: 'Stack Overflow - Memory Management', 
        url: 'https://stackoverflow.com/questions/tagged/memory-management',
        description: 'Community Q&A on implementation'
      }
    ],

    questions: [
      { 
        question: 'Explain the difference between logical and physical addresses with MMU role.', 
        answer: 'Logical address: generated by CPU, used by processes, virtual address space (e.g., 0 to 2^32-1). Physical address: actual RAM location, used by hardware. MMU (Memory Management Unit) translates logical to physical using page tables or segment tables. Example: Process accesses logical 0x1000, MMU translates to physical 0x5000. Benefits: process isolation, virtual memory, relocation.' 
      },
      { 
        question: 'Compare First Fit, Best Fit, and Worst Fit allocation algorithms.', 
        answer: 'First Fit: allocate first sufficient block. Fast (stops when found), may leave small fragments at start. Best Fit: allocate smallest sufficient block. Minimizes waste, slow (searches all), creates tiny fragments. Worst Fit: allocate largest block. Leaves larger fragments, slow (searches all), poor utilization. First Fit generally best balance of speed and efficiency.' 
      },
      { 
        question: 'What is fragmentation? Explain internal vs external fragmentation with solutions.', 
        answer: 'Internal fragmentation: wasted space within allocated block. Example: process needs 18KB, gets 20KB partition → 2KB wasted. Solution: smaller allocation units, variable partitioning. External fragmentation: free memory scattered in small non-contiguous blocks. Example: 100KB free in 10KB chunks, cannot allocate 50KB. Solution: compaction (expensive), paging (eliminates it), buddy system.' 
      },
      { 
        question: 'How does paging work? Explain address translation with example.', 
        answer: 'Paging divides logical memory into fixed-size pages and physical memory into frames (same size, typically 4KB). Page table maps pages to frames. Address translation: Logical address = (page number, offset). Example: 32-bit address, 4KB pages. Address 0x00003ABC: page 3, offset 0xABC (2748). If page 3 → frame 7: physical = (7 × 4096) + 2748 = 0x00007ABC. Eliminates external fragmentation.' 
      },
      { 
        question: 'What is TLB and why is it important? Calculate effective access time.', 
        answer: 'TLB (Translation Lookaside Buffer): small, fast cache of recent page table entries. Without TLB: 2 memory accesses (page table + data). With TLB: 1 access on hit. Example: TLB hit ratio 90%, TLB access 1ns, memory access 100ns. Effective time = 0.9(1+100) + 0.1(1+100+100) = 90.9 + 20.1 = 111ns vs 200ns without TLB. Critical for performance.' 
      },
      { 
        question: 'Explain multi-level paging and why it is used.', 
        answer: 'Problem: Large page tables consume memory. Example: 32-bit address, 4KB pages → 1M entries × 4 bytes = 4MB per process. Solution: Two-level paging. Logical address = (outer page 10 bits, inner page 10 bits, offset 12 bits). Outer table always in memory (4KB), inner tables paged. Saves memory: only need outer + active inner tables. Three-level for 64-bit systems.' 
      },
      { 
        question: 'How does segmentation differ from paging? Advantages and disadvantages.', 
        answer: 'Paging: fixed-size pages, no external fragmentation, hardware-centric, no logical division. Segmentation: variable-size segments (code, data, stack), matches program structure, programmer-centric, external fragmentation. Advantages: logical protection, easy sharing, dynamic growth. Disadvantages: complex allocation, fragmentation. Modern systems: segmentation with paging (Intel x86) - logical segments, each paged.' 
      },
      { 
        question: 'Explain demand paging and page fault handling steps.', 
        answer: 'Demand paging: load pages only when accessed. Page fault handling: 1) Check if reference valid (page table), 2) If invalid, terminate process, 3) If valid but not in memory: find free frame, 4) If no free frame, select victim (page replacement), 5) Write victim to disk if modified (dirty bit), 6) Load required page from disk, 7) Update page table, 8) Restart instruction. Enables virtual memory.' 
      },
      { 
        question: 'Compare page replacement algorithms: FIFO, Optimal, LRU, Clock.', 
        answer: 'FIFO: replace oldest page. Simple (queue), suffers Belady anomaly (more frames → more faults), poor performance. Optimal: replace page unused longest. Best performance, impossible (needs future knowledge), theoretical benchmark. LRU: replace least recently used. Good performance, approximates optimal, expensive (timestamps/stack). Clock (Second Chance): circular scan with reference bits. Efficient LRU approximation, hardware support, most practical.' 
      },
      { 
        question: 'What is thrashing? Causes, effects, and solutions.', 
        answer: 'Thrashing: process spends more time paging than executing. Causes: too many processes, each gets too few frames, constant page faults. Effects: CPU utilization drops, system becomes unresponsive. Solutions: 1) Reduce multiprogramming degree, 2) Working set model: allocate enough frames for working set, 3) Page fault frequency control: monitor fault rate, adjust allocation, 4) Local replacement: prevent one process affecting others. Working set: pages currently being used by process.' 
      }
    ]
  }
];
